# Skill: Evaluate Classifier

## Goal
Evaluate the performance of a trained classification model on the Wine dataset using appropriate metrics and visualizations.

## Steps
1.  **Input**: Accept the trained model, test features, and true labels as input.
2.  **Predictions**: Generate predictions on the test set.
3.  **Accuracy**: Calculate and report the overall accuracy.
4.  **Precision, Recall, F1-score**: Calculate and report precision, recall, and F1-score for each class, and their weighted averages.
5.  **Confusion Matrix**: Generate and visualize the confusion matrix to understand classification performance per class.
6.  **Classification Report**: Generate a comprehensive `sklearn.metrics.classification_report`.
7.  **ROC Curve (if applicable)**: If the model supports probability predictions, plot the ROC curve for each class (one-vs-rest) and calculate AUC scores.
8.  **Report Findings**: Summarize the model's performance, highlighting its strengths and weaknesses, and areas for improvement.
